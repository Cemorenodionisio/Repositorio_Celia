{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "adaptive-irrigation",
      "metadata": {
        "toc": true
      },
      "source": [
        "<h1>Índice<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introducción\" data-toc-modified-id=\"Introducción-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introducción</a></span></li><li><span><a href=\"#Instalación\" data-toc-modified-id=\"Instalación-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Instalación</a\n",
        "></span></li><li><span><a href=\"#Introducción-a-las-estructuras-de-datos-de-pandas\" data-toc-modified-id=\"Introducción-a-las-estructuras-de-datos-de-pandas-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Introducción a las estructuras de datos de pandas</a></span><ul class=\"toc-item\"><li><span><a href=\"#Series\" data-toc-modified-id=\"Series-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Serie</a></span></li><li><span><a href=\"#Dataframes\" data-toc-modified-id=\"Dataframes-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Dataframes</a></span><ul class=\"toc-item\"><li><span><a href=\"#From-data-types\" data-toc-modified-id=\"From-data-types-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>De tipos de datos</a></span></li><li><span><a href=\"#From-path\" data-toc-modified-id=\"From-path-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>De ruta</a></span></li><li><span><a href=\"#From-databases\" data-toc-modified-id=\"From-databases-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>De bases de datos</a></span></li></ul></li></ul></li><li><span><a href=\"#Exploratory-analysis-of-a-dataframe\" data-toc-modified-id=\"Análisis-exploratorio-de-un-dataframe-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Análisis exploratorio de un dataframe</a></span><ul class=\"toc-item\"><li><span><a href=\"#Metainformación\" data-toc-modified-id=\"Metainformación-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Metainformación</a></span></li><li><span><a href=\"#Previsualización\" data-toc-modified-id=\"Previsualización-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Previsualización</a></span></li><li><span><a href=\"#Order-a-dataframe\" data-toc-modified-id=\"Order-a-dataframe-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Ordenar un marco de datos</a></span></li><li><span><a href=\"#NaN-values\" data-toc-modified-id=\"NaN-values-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Valores NaN</a></span></li><li><span><a href=\"#Basic-descriptive-statistics\" data-toc-modified-id=\"Basic-descriptive-statistics-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Valores descriptivos básicos estadísticas</a></span></li></ul></li><li><span><a href=\"#Pandas-usual-methods\" data-toc-modified-id=\"Pandas-usual-methods-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Métodos habituales de Pandas</a></span></li><li><span><a href=\"#Further-materials\" data-toc-modified-id=\"Further-materials-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Materiales adicionales</a></span></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "anonymous-academy",
      "metadata": {},
      "source": [
        "# Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "751721df",
      "metadata": {
        "lang": "en"
      },
      "source": [
        "## Introducción\n",
        "Pandas es sin duda la librería más utilizada en el ecosistema Python para la manipulación y análisis de datos. Es rápida, potente, flexible, fácil de usar y de código abierto.\n",
        "\n",
        "Entre sus principales características:\n",
        "\n",
        "- Un objeto **DataFrame** rápido y eficiente para la manipulación de datos con indexación incorporada*\n",
        "\n",
        "- **Lectura y escritura** de datos en múltiples formatos: Microsoft Excel, CSV, bases de datos SQL, etc.;\n",
        "\n",
        "- Métodos integrados y eficientes para todo tipo de manipulación de datos: datos faltantes, subconjunto, unión, fusión, etc.;\n",
        "\n",
        "- Facilidad para trabajar con datos temporales (de hecho, Pandas debe su nombre a \"PANnel DAta\")\n",
        "\n",
        "- Buena **integración con otras librerías de análisis de datos o Machine learning**: scikit-learn, scipy, seaborn, plotly, etc.;\n",
        "\n",
        "- Es **ampliamente utilizada** tanto en el sector privado como en el académico\n",
        "\n",
        "Pandas proporciona estructuras de datos de alto nivel y funciones diseñadas para hacer que trabajar con datos estructurados o tabulares sea rápido, fácil y expresivo. Desde su introducción en 2010, ha ayudado a convertir Python en un entorno de análisis de datos potente y productivo. Los principales objetos de pandas que se utilizarán en este libro son DataFrame, una estructura de datos tabular orientada a columnas con etiquetas de filas y columnas, y Series, un objeto de matriz unidimensional etiquetado.\n",
        "\n",
        "Pandas combina las ideas de alto rendimiento de NumPy con las capacidades flexibles de manipulación de datos de las hojas de cálculo y las bases de datos relacionales (como SQL). Proporciona una funcionalidad de indexación sofisticada para facilitar la remodelación, el corte y el análisis, la realización de agregaciones y la selección de subconjuntos de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hourly-nutrition",
      "metadata": {},
      "source": [
        "![imagen](https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fgilpress%2Ffiles%2F2016%2F03%2FTime-1200x511.jpg)\n",
        "\n",
        "Fuente: [Forbes](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-ducing-least-enjoyable-data-science-task-survey-says/#1ba071616f63)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6680d33",
      "metadata": {
        "lang": "en"
      },
      "source": [
        "## Instalación"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58d0e351",
      "metadata": {
        "lang": "en"
      },
      "source": [
        "Lo primero que debes hacer siempre será\n",
        "`pip install pandas`, `conda install pandas`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "psychological-theorem",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "960d4f4b",
      "metadata": {
        "lang": "en"
      },
      "source": [
        "## Introducción a las estructuras de datos de Pandas\n",
        "Para comenzar a usar Pandas, deberá familiarizarse con sus dos estructuras de datos funcionales: Series y DataFrame. Si bien no son una solución universal para todos los problemas, brindan una base sólida y fácil de usar para la mayoría de las aplicaciones."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d636439c",
      "metadata": {
        "lang": "en"
      },
      "source": [
        "### Serie\n",
        "Una Serie es un objeto de matriz unidimensional que contiene una secuencia de valores (de tipos similares a NumPy) y una matriz asociada de etiquetas de datos, llamada su índice. La Serie más simple se forma a partir de una única matriz de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "40e495e1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([10, 20, 30, 40]), RangeIndex(start=0, stop=4, step=1))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datos = [10, 20, 30, 40]\n",
        "serie = pd.Series(datos)\n",
        "serie.values, serie.index #empieza en el 0, hay 4 elementos y va de unno en uno "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8006ecb",
      "metadata": {
        "lang": "en"
      },
      "source": [
        "La representación de cadena de una serie que se muestra de forma interactiva muestra el índice a la izquierda y los valores a la derecha. Como no especificamos un índice para los datos, se crea uno predeterminado que consta de los números enteros de 0 a N - 1 (donde N es la longitud de los datos). Puede obtener la representación de matriz y el objeto de índice de la serie a través de sus valores y atributos de índice, respectivamente:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24f739f4",
      "metadata": {
        "lang": "en"
      },
      "source": [
        "Otra forma de pensar en una Serie es como un diccionario ordenado de longitud fija, ya que es una asignación de valores de índice a valores de datos. Se puede utilizar en muchos contextos en los que se podría utilizar un diccionario.\n",
        "Si tienes datos contenidos en un diccionario de Python, puedes crear una Serie a partir de ellos pasando el diccionario:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ae45df01",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Madrid       1.5\n",
              "Barcelona    3.4\n",
              "Sevilla      1.2\n",
              "dtype: float64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datos_dicc = {\"Madrid\": 1.5, \"Barcelona\": 3.4, \"Sevilla\": 1.2}\n",
        "serie_dicc =pd.Series(datos_dicc)\n",
        "serie_dicc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb3ede87",
      "metadata": {
        "lang": "en"
      },
      "source": [
        "Cuando solo se pasa un diccionario, el índice de cadena resultante tendrá las claves del diccionario en orden. Puede anular esto pasando las claves del diccionario en el orden en que desea que aparezcan en la cadena resultante:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73a97ba9",
      "metadata": {
        "lang": "en"
      },
      "source": [
        "Aquí, los tres valores encontrados en sdata se colocaron en los lugares correspondientes, pero como no se encontró ningún valor para \"California\", aparece como NaN (no es un número), lo que en pandas se considera que marca los valores faltantes o NA. Como \"Utah\" no se incluyó en los estados, se excluye del objeto resultante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b3c3909b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Barcelona    3.4\n",
              "Sevilla      1.2\n",
              "Cáceres      NaN\n",
              "dtype: float64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ciudades_seleccion = [\"Barcelona\", \"Sevilla\", \"Cáceres\"]\n",
        "serie = pd.Series(datos_dicc, index = ciudades_seleccion)\n",
        "#si la seleccion no esta entonces me lo pasa como null\n",
        "serie"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6686773c",
      "metadata": {
        "lang": "en"
      },
      "source": [
        "### Dataframes\n",
        "Pandas puede leer y escribir datos de una amplia variedad de formatos. [Lea la documentación](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html)\n",
        "Aunque uno de los más comunes es a partir de un diccionario de listas de igual longitud o matrices NumPy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "c9e956d8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Estado</th>\n",
              "      <th>Año</th>\n",
              "      <th>Población</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Utah</td>\n",
              "      <td>2002</td>\n",
              "      <td>1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ohio</td>\n",
              "      <td>2010</td>\n",
              "      <td>2.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>California</td>\n",
              "      <td>2025</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Estado   Año  Población\n",
              "0        Utah  2002        1.3\n",
              "1        Ohio  2010        2.7\n",
              "2  California  2025        NaN"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datos = {\n",
        "    \"Estado\" : [\"Utah\", \"Ohio\", \"California\"],\n",
        "    \"Año\" : [2002, 2010, 2025], \n",
        "    \"Población\" : [1.3, 2.7, None] \n",
        "    }\n",
        "df = pd.DataFrame(datos)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06ca0560",
      "metadata": {},
      "source": [
        "#### De los tipos de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12bcad45",
      "metadata": {},
      "source": [
        "`de diccionarios con listas como valores`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afe61aac",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nombres</th>\n",
              "      <th>Pais</th>\n",
              "      <th>Salario</th>\n",
              "      <th>Año</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Laura</td>\n",
              "      <td>España</td>\n",
              "      <td>23000</td>\n",
              "      <td>2000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sofia</td>\n",
              "      <td>Francia</td>\n",
              "      <td>6000</td>\n",
              "      <td>1997.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Raul</td>\n",
              "      <td>Alemania</td>\n",
              "      <td>20000</td>\n",
              "      <td>1960.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lucas</td>\n",
              "      <td>Portugal</td>\n",
              "      <td>8000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Nombres      Pais  Salario     Año\n",
              "0   Laura    España    23000  2000.0\n",
              "1   Sofia   Francia     6000  1997.0\n",
              "2    Raul  Alemania    20000  1960.0\n",
              "3   Lucas  Portugal     8000     NaN"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#DICCIONARIO DE LISTA\n",
        "datos_alumnos = {\n",
        "    \"Nombres\" :[\"Laura\", \"Sofia\", \"Raul\", \"Lucas\"],\n",
        "    \"Pais\" : [\"España\", \"Francia\", \"Alemania\", \"Portugal\"],\n",
        "    \"Salario\" : [23000, 6000, 20000, 8000],\n",
        "    \"Año\" : [2000, 1997, 1960, None] #PONGO None EN LOS VALORES DESCONOCIDOS\n",
        "}\n",
        "\n",
        "df_alumnos = pd.DataFrame(datos_alumnos)\n",
        "df_alumnos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52162b19",
      "metadata": {
        "lang": "en"
      },
      "source": [
        "Dado que utilizamos Jupyter Notebook, los objetos DataFrame de Pandas se mostrarán como una tabla HTML más compatible con el navegador. [Más información sobre esto](https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "3d3af879",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nombres</th>\n",
              "      <th>Pais</th>\n",
              "      <th>Salario</th>\n",
              "      <th>Año</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>laura</td>\n",
              "      <td>España</td>\n",
              "      <td>23000</td>\n",
              "      <td>2000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sofia</td>\n",
              "      <td>Francia</td>\n",
              "      <td>6000</td>\n",
              "      <td>1997.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>raul</td>\n",
              "      <td>Alemania</td>\n",
              "      <td>20000</td>\n",
              "      <td>1960.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lucas</td>\n",
              "      <td>Portugal</td>\n",
              "      <td>8000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Nombres      Pais  Salario     Año\n",
              "0   laura    España    23000  2000.0\n",
              "1   sofia   Francia     6000  1997.0\n",
              "2    raul  Alemania    20000  1960.0\n",
              "3   lucas  Portugal     8000     NaN"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#LISTA DE DICCIONARIOS\n",
        "datos_alumnos2 = [{\"Nombres\" :\"Laura\", \"Pais\" : \"España\", \"Salario\" : 23000, \"Año\" : 2000}, \n",
        "    {\"Nombres\" :\"Sofia\", \"Pais\" : \"Francia\", \"Salario\" : 6000, \"Año\" : 1997},\n",
        "    {\"Nombres\" :\"Raul\", \"Pais\" : \"Alemania\", \"Salario\" : 20000, \"Año\" : 1960},\n",
        "    {\"Nombres\" :\"Lucas\", \"Pais\" : \"Portugal\", \"Salario\" : 8000}] #FALTA EL AÑO Y ME LO AUTOCOMPLETA\n",
        "df_alumnos2 = pd.DataFrame(datos_alumnos2)\n",
        "df_alumnos2[\"Nombres\"] = df_alumnos2[\"Nombres\"].replace(\"Raul\", \"RAUL\")\n",
        "df_alumnos2.loc[df_alumnos2[\"Nombres\"] == \"Lucas\", \"Nombres\"] = \"LUCAS\"\n",
        "df_alumnos2.at[0, \"Nombres\"] = \"LAURA\"  # Cambia la primera fila\n",
        "df_alumnos2[\"Nombres\"] = df_alumnos2[\"Nombres\"].str.lower() #CAMBIAMOS TODOS\n",
        "\n",
        "df_alumnos2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "924018c0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Nombres      Pais  Salario     Año\n",
            "0   Laura    España    23000  2000.0\n",
            "1   Sofia   Francia     6000  1997.0\n",
            "2    Raul  Alemania    20000  1960.0\n",
            "3   Lucas  Portugal     8000  2025.0\n"
          ]
        }
      ],
      "source": [
        "datos_alumnos2 = [{\"Nombres\" :\"Laura\", \"Pais\" : \"España\", \"Salario\" : 23000, \"Año\" : 2000}, \n",
        "    {\"Nombres\" :\"Sofia\", \"Pais\" : \"Francia\", \"Salario\" : 6000, \"Año\" : 1997},\n",
        "    {\"Nombres\" :\"Raul\", \"Pais\" : \"Alemania\", \"Salario\" : 20000, \"Año\" : 1960},\n",
        "    {\"Nombres\" :\"Lucas\", \"Pais\" : \"Portugal\", \"Salario\" : 8000, \"Año\": None}] #FALTA EL AÑO Y ME LO AUTOCOMPLETA\n",
        "\n",
        "datos_extras = [{\"Nombres\": \"Lucas\", \"Año\": 2025}]\n",
        "\n",
        "df_alumnos2 = pd.DataFrame(datos_alumnos2)\n",
        "df_extra = pd.DataFrame(datos_extras)\n",
        "\n",
        "# tengo que crear una nueva columna con el mismo nombre y los valores nuevos y depsues unirlo y borrar la ultima que he creado \n",
        "df_all = df_alumnos2.merge(df_extra, on=\"Nombres\", how=\"left\", suffixes=(\"\", \"_nuevo\"))\n",
        "df_all[\"Año\"] = df_all[\"Año\"].combine_first(df_all[\"Año_nuevo\"])\n",
        "df_all = df_all.drop(columns=\"Año_nuevo\") \n",
        "# how = \"left\" para mantener -> conservar todos los alumnos\n",
        "print( df_all)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7c63fee",
      "metadata": {},
      "source": [
        "[pandas desde dict](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_dict.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fbaae69",
      "metadata": {
        "lang": "en"
      },
      "source": [
        "#### Desde la ruta"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8818e830",
      "metadata": {},
      "source": [
        "`.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "bcfd7903",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 8 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   Customer_ID!!       682 non-null    object\n",
            " 1   Purchase_Date###    912 non-null    object\n",
            " 2    Product category   747 non-null    object\n",
            " 3   Amount_Paid_($)@@   608 non-null    object\n",
            " 4   Discount applied@@  883 non-null    object\n",
            " 5   COUNTRY!!           1000 non-null   object\n",
            " 6   City###             890 non-null    object\n",
            " 7   CUSTOMER REVIEW     819 non-null    object\n",
            "dtypes: object(8)\n",
            "memory usage: 62.6+ KB\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Customer_ID!!</th>\n",
              "      <th>Purchase_Date###</th>\n",
              "      <th>Product category</th>\n",
              "      <th>Amount_Paid_($)@@</th>\n",
              "      <th>Discount applied@@</th>\n",
              "      <th>COUNTRY!!</th>\n",
              "      <th>City###</th>\n",
              "      <th>CUSTOMER REVIEW</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>NaN</td>\n",
              "      <td>20-05-2023</td>\n",
              "      <td>Clothing</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Canada</td>\n",
              "      <td>Berlin</td>\n",
              "      <td>Meh, it's okay.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>596</td>\n",
              "      <td>19-03-2023</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>USA</td>\n",
              "      <td>Madrid</td>\n",
              "      <td>Worst purchase ever.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>597a</td>\n",
              "      <td>2023/09/17</td>\n",
              "      <td>Home</td>\n",
              "      <td>$278</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mexico</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Totally worth it!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>598a</td>\n",
              "      <td>2023/03/05</td>\n",
              "      <td>NaN</td>\n",
              "      <td>108$</td>\n",
              "      <td>True</td>\n",
              "      <td>Germany</td>\n",
              "      <td>New York</td>\n",
              "      <td>Arrived late, but good quality.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>599a</td>\n",
              "      <td>2023/12/16</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>11$</td>\n",
              "      <td>NaN</td>\n",
              "      <td>USA</td>\n",
              "      <td>Madrid</td>\n",
              "      <td>Amazing!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Customer_ID!! Purchase_Date###  Product category Amount_Paid_($)@@  \\\n",
              "995           NaN       20-05-2023          Clothing               NaN   \n",
              "996           596       19-03-2023               NaN               NaN   \n",
              "997          597a       2023/09/17              Home              $278   \n",
              "998          598a       2023/03/05               NaN              108$   \n",
              "999          599a       2023/12/16       Electronics               11$   \n",
              "\n",
              "    Discount applied@@ COUNTRY!!   City###                CUSTOMER REVIEW    \n",
              "995                Yes    Canada    Berlin                  Meh, it's okay.  \n",
              "996              False       USA    Madrid             Worst purchase ever.  \n",
              "997                Yes    Mexico       NaN                Totally worth it!  \n",
              "998               True   Germany  New York  Arrived late, but good quality.  \n",
              "999                NaN       USA    Madrid                         Amazing!  "
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"/Users/macbook/Desktop/data science /evolve-data-python/datasets/business.csv\")\n",
        "df.shape\n",
        "df.head(10)# ve las 5 primeras por opmision, si pongo un número me da los N primeros\n",
        "df.describe() #descriptiva top: valor mas repetido, frecuencia: cuantas veces se repite\n",
        "df.info() #ver otra info como los nulos que hay \n",
        "df.columns #nombres de las columnas\n",
        "df.dtypes #tipos de la columnas\n",
        "df.tail() #ver el final "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "985db2a6",
      "metadata": {},
      "source": [
        "`.xlsx`, `xls`, `xlsm`, `xlsb`, `odf`, `ods`, `odt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd11fb1b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   InvoiceNo         InvoiceNo.1 InvoiceNo.2  \\\n",
            "0     536365 2010-12-01 08:26:00      85123A   \n",
            "1     536373 2010-12-01 09:02:00      85123A   \n",
            "2     536375 2010-12-01 09:32:00      85123A   \n",
            "3     536390 2010-12-01 10:19:00      85123A   \n",
            "4     536394 2010-12-01 10:39:00      85123A   \n",
            "\n",
            "                          InvoiceNo.3  InvoiceNo.4  InvoiceNo.5  InvoiceNo.6  \\\n",
            "0  CREAM HANGING HEART T-LIGHT HOLDER            6         2.55         15.3   \n",
            "1  CREAM HANGING HEART T-LIGHT HOLDER            6         2.55         15.3   \n",
            "2  CREAM HANGING HEART T-LIGHT HOLDER            6         2.55         15.3   \n",
            "3  CREAM HANGING HEART T-LIGHT HOLDER           64         2.55        163.2   \n",
            "4  CREAM HANGING HEART T-LIGHT HOLDER           32         2.55         81.6   \n",
            "\n",
            "   InvoiceNo.7     InvoiceNo.8  \n",
            "0        17850  United Kingdom  \n",
            "1        17850  United Kingdom  \n",
            "2        17850  United Kingdom  \n",
            "3        17511  United Kingdom  \n",
            "4        13408  United Kingdom  \n"
          ]
        }
      ],
      "source": [
        "#!python3.13 -m pip install openpyxl\n",
        "#!pip install --upgrade pip\n",
        "\n",
        "# Carga solo las primeras 1000 filas porque tarda mucho \n",
        "df_excel = pd.read_excel(\n",
        "    \"/Users/macbook/Desktop/data science /evolve-data-python/datasets/Online Retail.xlsx\",\n",
        "    nrows=10\n",
        ")\n",
        "print(df_excel.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "689486fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "#convertirlo a csv sin los indices\n",
        "df_excel.to_csv(\"/Users/macbook/Desktop/data science /evolve-data-python/datasets/Online Retail.xlsx\",\n",
        "     index= False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f9178b7",
      "metadata": {},
      "source": [
        "`Lectura de diferentes hojas`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ef0b2ac",
      "metadata": {},
      "source": [
        "`web`: https://raw.githubusercontent.com/datapackage-examples/sample-csv/master/sample.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13a9ea58",
      "metadata": {},
      "source": [
        "#### Desde bases de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ffcaa3c",
      "metadata": {},
      "source": [
        "`sql`: [documentación](https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2380f09",
      "metadata": {},
      "source": [
        "```python\n",
        "from sqlite3 import connect\n",
        "\n",
        "conn = connect(':memory:') # path\n",
        "df = pd.read_sql('SELECT columna_1, columna_2 FROM datos_de_muestra', conn)\n",
        "\n",
        "df.to_sql('datos_de_prueba', conn)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c92c595",
      "metadata": {},
      "source": [
        "``mongodb``"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "431cee4b",
      "metadata": {},
      "source": [
        "```python\n",
        "import pymongo\n",
        "from pymongo import MongoClient\n",
        "\n",
        "cliente = MongoClient()\n",
        "db = cliente.nombre_base_datos\n",
        "colección = db.nombre_colección\n",
        "datos = pd.DataFrame(list(colección.find()))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adf7fbf8",
      "metadata": {
        "lang": "en"
      },
      "source": [
        "## Análisis exploratorio de un DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b9482a5",
      "metadata": {},
      "source": [
        "### Metainformación"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9974075",
      "metadata": {},
      "source": [
        "`forma, columnas, tipos de datos, información, descripción`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96c0ddd3",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.shape\n",
        "df.head(10)# ve las 5 primeras por opmision, si pongo un número me da los N primeros\n",
        "df.describe() #descriptiva top: valor mas repetido, frecuencia: cuantas veces se repite\n",
        "df.info() #ver otra info como los nulos que hay \n",
        "df.columns #nombres de las columnas\n",
        "df.dtypes #tipos de la columnas\n",
        "df.tail() #ver el final "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df76790c",
      "metadata": {},
      "source": [
        "[Cómo funcionan los dtypes](https://numpy.org/doc/stable/reference/arrays.dtypes.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ee7446f",
      "metadata": {
        "lang": "en"
      },
      "source": [
        "### Valores NaN\n",
        "NaN significa Not A Number (no es un número) y es una de las formas más comunes de representar el valor faltante en los datos. Es un valor de punto flotante especial y no se puede convertir a un tipo distinto de float.\n",
        "El valor NaN es uno de los principales problemas en el análisis de datos. Es muy importante trabajar con NaN para obtener los resultados deseados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "337a177e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Customer_ID!!         318\n",
              "Purchase_Date###       88\n",
              " Product category     253\n",
              "Amount_Paid_($)@@     392\n",
              "Discount applied@@    117\n",
              "COUNTRY!!               0\n",
              "City###               110\n",
              "CUSTOMER REVIEW       181\n",
              "dtype: int64"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna() #si es Nulo me sa True y si no lo es False\n",
        "df.isna().sum()\n",
        "#df.dropna() #elimina todos los valores nulos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "4b63fd30",
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'CUSTOMER REVIEW  '",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mKeyError\u001b[39m: 'CUSTOMER REVIEW  '",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[115]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#df.fillna() #cambia los nulos por lo que nosotros digamos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mCUSTOMER REVIEW  \u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCUSTOMER REVIEW  \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.fillna(\u001b[33m\"\u001b[39m\u001b[33mNo review\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m df.head()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
            "\u001b[31mKeyError\u001b[39m: 'CUSTOMER REVIEW  '"
          ]
        }
      ],
      "source": [
        "#df.fillna() #cambia los nulos por lo que nosotros digamos\n",
        "df[\"CUSTOMER REVIEW  \"] = df[\"CUSTOMER REVIEW  \"].fillna(\"No review\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "8ea53e76",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Customer_ID!!</th>\n",
              "      <th>Purchase_Date###</th>\n",
              "      <th>Product category</th>\n",
              "      <th>Amount_Paid_($)@@</th>\n",
              "      <th>Discount applied@@</th>\n",
              "      <th>COUNTRY!!</th>\n",
              "      <th>City###</th>\n",
              "      <th>CuStOmEr ReWiEw</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100a</td>\n",
              "      <td>21-09-2023</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Toronto</td>\n",
              "      <td>Excellent product!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Rome</td>\n",
              "      <td>Customer service was awful.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2023/06/18</td>\n",
              "      <td>Clothing</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>Mexico</td>\n",
              "      <td>Paris</td>\n",
              "      <td>Worst purchase ever.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>103a</td>\n",
              "      <td>26-11-2023</td>\n",
              "      <td>Home</td>\n",
              "      <td>$200</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>Customer service was awful.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>104a</td>\n",
              "      <td>2023/11/16</td>\n",
              "      <td>Clothing</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>USA</td>\n",
              "      <td>Toronto</td>\n",
              "      <td>Customer service was awful.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>NaN</td>\n",
              "      <td>20-05-2023</td>\n",
              "      <td>Clothing</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Canada</td>\n",
              "      <td>Berlin</td>\n",
              "      <td>Meh, it's okay.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>596</td>\n",
              "      <td>19-03-2023</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>USA</td>\n",
              "      <td>Madrid</td>\n",
              "      <td>Worst purchase ever.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>597a</td>\n",
              "      <td>2023/09/17</td>\n",
              "      <td>Home</td>\n",
              "      <td>$278</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mexico</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Totally worth it!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>598a</td>\n",
              "      <td>2023/03/05</td>\n",
              "      <td>NaN</td>\n",
              "      <td>108$</td>\n",
              "      <td>True</td>\n",
              "      <td>Germany</td>\n",
              "      <td>New York</td>\n",
              "      <td>Arrived late, but good quality.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>599a</td>\n",
              "      <td>2023/12/16</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>11$</td>\n",
              "      <td>NaN</td>\n",
              "      <td>USA</td>\n",
              "      <td>Madrid</td>\n",
              "      <td>Amazing!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Customer_ID!! Purchase_Date###  Product category Amount_Paid_($)@@  \\\n",
              "0            100a       21-09-2023       Electronics               NaN   \n",
              "1             NaN              NaN               NaN               NaN   \n",
              "2             NaN       2023/06/18          Clothing               NaN   \n",
              "3            103a       26-11-2023              Home              $200   \n",
              "4            104a       2023/11/16          Clothing               NaN   \n",
              "..            ...              ...               ...               ...   \n",
              "995           NaN       20-05-2023          Clothing               NaN   \n",
              "996           596       19-03-2023               NaN               NaN   \n",
              "997          597a       2023/09/17              Home              $278   \n",
              "998          598a       2023/03/05               NaN              108$   \n",
              "999          599a       2023/12/16       Electronics               11$   \n",
              "\n",
              "    Discount applied@@ COUNTRY!!      City###                  CuStOmEr ReWiEw  \n",
              "0                 True   Germany      Toronto               Excellent product!  \n",
              "1                 True     Spain         Rome      Customer service was awful.  \n",
              "2                 True    Mexico        Paris             Worst purchase ever.  \n",
              "3                  Yes   Germany  Los Angeles      Customer service was awful.  \n",
              "4                False       USA      Toronto      Customer service was awful.  \n",
              "..                 ...       ...          ...                              ...  \n",
              "995                Yes    Canada       Berlin                  Meh, it's okay.  \n",
              "996              False       USA       Madrid             Worst purchase ever.  \n",
              "997                Yes    Mexico          NaN                Totally worth it!  \n",
              "998               True   Germany     New York  Arrived late, but good quality.  \n",
              "999                NaN       USA       Madrid                         Amazing!  \n",
              "\n",
              "[1000 rows x 8 columns]"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#cambiar el nombre de la columna\n",
        "df = df.rename(columns= {\"CUSTOMER REVIEW  \" : \"CuStOmEr ReWiEw\"})\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cf99e9d",
      "metadata": {},
      "source": [
        "# HANDS-ON"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3f402c7",
      "metadata": {},
      "source": [
        "## Ventas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f072a5a",
      "metadata": {},
      "source": [
        "1.\tObtener las 5 ventas más altas en términos de Total_Venta.\n",
        "2.\tFiltrar todas las ventas de la categoría “Electrónica” con más de 5 unidades vendidas.\n",
        "3.\tCalcular el ingreso total por cada sucursal.\n",
        "4.\tObtener el producto más vendido en cantidad.\n",
        "5.\tObtener la venta promedio por día.\n",
        "6.\tCalcular desviación estándar del precio unitario por categoría."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "721330a6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Fecha', 'Producto', 'Categoría', 'Precio_Unitario', 'Cantidad',\n",
              "       'Sucursal', 'Total_Venta'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def generar_dataset_ventas ():\n",
        "    np.random.seed(42) #SEMILLA PARA QUE NOS SALGA A TODOS MUY SIMILARES\n",
        "    fechas = pd.date_range(start=\"2023-01-01\", periods=500, freq=\"D\")\n",
        "    productos = [\"Laptop\", \"Teléfono\", \"Tablet\", \"Monitor\", \"Teclado\", \"Ratón\"]\n",
        "    categorias = [\"Electrónica\", \"Accesorios\"]\n",
        "    data = {\n",
        "        \"Fecha\": np.random.choice(fechas, 5000),\n",
        "        \"Producto\": np.random.choice(productos, 5000),\n",
        "        \"Categoría\": np.random.choice(categorias, 5000, p=[0.7, 0.3]),\n",
        "        \"Precio_Unitario\": np.random.randint(50, 2000, 5000),\n",
        "        \"Cantidad\": np.random.randint(1, 10, 5000),\n",
        "        \"Sucursal\": np.random.choice([\"Madrid\", \"Barcelona\", \"Valencia\", \"Sevilla\"], 5000),\n",
        "    }\n",
        "\n",
        "    df_ventas = pd.DataFrame(data)\n",
        "    df_ventas[\"Total_Venta\"] = df_ventas[\"Precio_Unitario\"] * df_ventas[\"Cantidad\"]\n",
        "    df_ventas.sort_values(\"Fecha\", inplace=True)\n",
        "    return df_ventas\n",
        "\n",
        "df_ventas = generar_dataset_ventas ()\n",
        "df_ventas.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "e2c6648b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fecha</th>\n",
              "      <th>Producto</th>\n",
              "      <th>Categoría</th>\n",
              "      <th>Precio_Unitario</th>\n",
              "      <th>Cantidad</th>\n",
              "      <th>Sucursal</th>\n",
              "      <th>Total_Venta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4937</th>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>Laptop</td>\n",
              "      <td>Electrónica</td>\n",
              "      <td>1268</td>\n",
              "      <td>1</td>\n",
              "      <td>Barcelona</td>\n",
              "      <td>1268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>930</th>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>Teclado</td>\n",
              "      <td>Electrónica</td>\n",
              "      <td>904</td>\n",
              "      <td>7</td>\n",
              "      <td>Valencia</td>\n",
              "      <td>6328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>891</th>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>Tablet</td>\n",
              "      <td>Accesorios</td>\n",
              "      <td>829</td>\n",
              "      <td>6</td>\n",
              "      <td>Madrid</td>\n",
              "      <td>4974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1576</th>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>Teléfono</td>\n",
              "      <td>Accesorios</td>\n",
              "      <td>1348</td>\n",
              "      <td>8</td>\n",
              "      <td>Madrid</td>\n",
              "      <td>10784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2754</th>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>Tablet</td>\n",
              "      <td>Electrónica</td>\n",
              "      <td>592</td>\n",
              "      <td>8</td>\n",
              "      <td>Sevilla</td>\n",
              "      <td>4736</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Fecha  Producto    Categoría  Precio_Unitario  Cantidad   Sucursal  \\\n",
              "4937 2023-01-01    Laptop  Electrónica             1268         1  Barcelona   \n",
              "930  2023-01-01   Teclado  Electrónica              904         7   Valencia   \n",
              "891  2023-01-01    Tablet   Accesorios              829         6     Madrid   \n",
              "1576 2023-01-01  Teléfono   Accesorios             1348         8     Madrid   \n",
              "2754 2023-01-01    Tablet  Electrónica              592         8    Sevilla   \n",
              "\n",
              "      Total_Venta  \n",
              "4937         1268  \n",
              "930          6328  \n",
              "891          4974  \n",
              "1576        10784  \n",
              "2754         4736  "
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ORDENO POR LA COLUMNA DE TOTAL VENTAS\n",
        "df_ordenado = df_ventas.sort_values(by=\"Total_Venta\", ascending=False, inplace=False)\n",
        "\n",
        "# MOSTRAR LOS 5 CON MAYOR TOTAL VENTA\n",
        "df_ventas.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b249054",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fecha</th>\n",
              "      <th>Producto</th>\n",
              "      <th>Categoría</th>\n",
              "      <th>Precio_Unitario</th>\n",
              "      <th>Cantidad</th>\n",
              "      <th>Sucursal</th>\n",
              "      <th>Total_Venta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>930</th>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>Teclado</td>\n",
              "      <td>Electrónica</td>\n",
              "      <td>904</td>\n",
              "      <td>7</td>\n",
              "      <td>Valencia</td>\n",
              "      <td>6328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2754</th>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>Tablet</td>\n",
              "      <td>Electrónica</td>\n",
              "      <td>592</td>\n",
              "      <td>8</td>\n",
              "      <td>Sevilla</td>\n",
              "      <td>4736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1344</th>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>Teléfono</td>\n",
              "      <td>Electrónica</td>\n",
              "      <td>439</td>\n",
              "      <td>8</td>\n",
              "      <td>Barcelona</td>\n",
              "      <td>3512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>Monitor</td>\n",
              "      <td>Electrónica</td>\n",
              "      <td>898</td>\n",
              "      <td>7</td>\n",
              "      <td>Valencia</td>\n",
              "      <td>6286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4513</th>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>Teléfono</td>\n",
              "      <td>Electrónica</td>\n",
              "      <td>846</td>\n",
              "      <td>6</td>\n",
              "      <td>Sevilla</td>\n",
              "      <td>5076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1733</th>\n",
              "      <td>2024-05-14</td>\n",
              "      <td>Teclado</td>\n",
              "      <td>Electrónica</td>\n",
              "      <td>149</td>\n",
              "      <td>9</td>\n",
              "      <td>Madrid</td>\n",
              "      <td>1341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1460</th>\n",
              "      <td>2024-05-14</td>\n",
              "      <td>Teléfono</td>\n",
              "      <td>Electrónica</td>\n",
              "      <td>234</td>\n",
              "      <td>8</td>\n",
              "      <td>Madrid</td>\n",
              "      <td>1872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4257</th>\n",
              "      <td>2024-05-14</td>\n",
              "      <td>Ratón</td>\n",
              "      <td>Electrónica</td>\n",
              "      <td>648</td>\n",
              "      <td>8</td>\n",
              "      <td>Madrid</td>\n",
              "      <td>5184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>647</th>\n",
              "      <td>2024-05-14</td>\n",
              "      <td>Monitor</td>\n",
              "      <td>Electrónica</td>\n",
              "      <td>1775</td>\n",
              "      <td>8</td>\n",
              "      <td>Valencia</td>\n",
              "      <td>14200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1779</th>\n",
              "      <td>2024-05-14</td>\n",
              "      <td>Laptop</td>\n",
              "      <td>Electrónica</td>\n",
              "      <td>1920</td>\n",
              "      <td>9</td>\n",
              "      <td>Sevilla</td>\n",
              "      <td>17280</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1540 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Fecha  Producto    Categoría  Precio_Unitario  Cantidad   Sucursal  \\\n",
              "930  2023-01-01   Teclado  Electrónica              904         7   Valencia   \n",
              "2754 2023-01-01    Tablet  Electrónica              592         8    Sevilla   \n",
              "1344 2023-01-01  Teléfono  Electrónica              439         8  Barcelona   \n",
              "1397 2023-01-01   Monitor  Electrónica              898         7   Valencia   \n",
              "4513 2023-01-01  Teléfono  Electrónica              846         6    Sevilla   \n",
              "...         ...       ...          ...              ...       ...        ...   \n",
              "1733 2024-05-14   Teclado  Electrónica              149         9     Madrid   \n",
              "1460 2024-05-14  Teléfono  Electrónica              234         8     Madrid   \n",
              "4257 2024-05-14     Ratón  Electrónica              648         8     Madrid   \n",
              "647  2024-05-14   Monitor  Electrónica             1775         8   Valencia   \n",
              "1779 2024-05-14    Laptop  Electrónica             1920         9    Sevilla   \n",
              "\n",
              "      Total_Venta  \n",
              "930          6328  \n",
              "2754         4736  \n",
              "1344         3512  \n",
              "1397         6286  \n",
              "4513         5076  \n",
              "...           ...  \n",
              "1733         1341  \n",
              "1460         1872  \n",
              "4257         5184  \n",
              "647         14200  \n",
              "1779        17280  \n",
              "\n",
              "[1540 rows x 7 columns]"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#FIlTRAR ELECTRONICA CON MAS DE 5 UNIDADES VENDIDAS\n",
        "'''\n",
        "df_ventas[\"Categoría\"] == \"Electrónica\") ESTO ME DA UN LISTADO DE TRUE Y FALSE Y AL METERLO EN DF[] SELECCIONO SOLO LOS TRUE\n",
        "'''\n",
        "df_ventas_mas5 = df_ventas[(df_ventas[\"Categoría\"] == \"Electrónica\") & (df_ventas[\"Cantidad\"] > 5)]\n",
        "df_ventas_mas5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "id": "c350d0e8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sucursal\n",
              "Barcelona    6161071\n",
              "Madrid       6127251\n",
              "Sevilla      6747435\n",
              "Valencia     6411507\n",
              "Name: Total_Venta, dtype: int64"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# HACER RECUENTO DEL TOTAL POR SUCURSAL\n",
        "df_ventas.groupby(\"Sucursal\")[\"Total_Venta\"].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "id": "bde1f463",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Producto más vendido: Ratón (4287 unidades)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Ratón'"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# PRODUCTO MÁS VENDIDO SEGUN LA CANTIDAD\n",
        "ventas_por_producto = df_ventas.groupby(\"Producto\")[\"Cantidad\"].sum()\n",
        "producto_mas_vendido = ventas_por_producto.idxmax()\n",
        "cantidad_vendida = ventas_por_producto.max()\n",
        "print(f\"Producto más vendido: {producto_mas_vendido} ({cantidad_vendida} unidades)\")\n",
        "df_ventas.groupby(\"Producto\")[\"Cantidad\"].sum().idxmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "id": "9cd3bd1c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Fecha\n",
              "2023-01-01    5532.071429\n",
              "Name: Total_Venta, dtype: float64"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# OBTENER VENTA PROMEDIO POR DÍA\n",
        "df_xdia = df_ventas.groupby(\"Fecha\")[\"Total_Venta\"].mean().head(1)\n",
        "df_xdia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "81062284",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Categoría\n",
              "Accesorios    565.029215\n",
              "Name: Precio_Unitario, dtype: float64"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# CALCULAR DESVIACIÓN ESTÁNDAR DEL PRECIO UNITARIO POR CATEGORIA\n",
        "df_ventas.groupby(\"Categoría\")[\"Precio_Unitario\"].std().head(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1cddfc4",
      "metadata": {},
      "source": [
        "## RRHH"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "570269de",
      "metadata": {},
      "source": [
        "1.\tObtener el empleado con mayor salario.\n",
        "2.\tFiltrar empleados con más de 10 años de experiencia y con salario superior a 50,000€.\n",
        "3.\tCalcular el salario promedio por departamento.\n",
        "4.\tObtener la cantidad de empleados por sucursal.\n",
        "5.\tEncontrar la edad promedio por cargo.\n",
        "6.\tFiltrar empleados de IT menores de 30 años.m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "d6549e50",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['ID', 'Nombre', 'Edad', 'Cargo', 'Departamento', 'Genero', 'Salario',\n",
              "       'Sucursal', 'Años_Experiencia'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def generar_dataset_rrhh():\n",
        "    np.random.seed(42)\n",
        "    cargos = [\"Analista\", \"Gerente\", \"Desarrollador\", \"Data Scientist\", \"Marketing\", \"Ventas\"]\n",
        "    departamentos = [\"IT\", \"RRHH\", \"Ventas\", \"Marketing\", \"Producción\"]\n",
        "    generos = [\"M\", \"F\", \"NB\"]\n",
        "    sucursales = [\"Madrid\", \"Barcelona\", \"Bilbao\", \"Sevilla\"]\n",
        "    data = {\n",
        "        \"ID\": np.arange(1, 3001),\n",
        "        \"Nombre\": np.random.choice([\"Luis\", \"Ana\", \"Carlos\", \"María\", \"David\", \"Laura\"], 3000),\n",
        "        \"Edad\": np.random.randint(22, 60, 3000),\n",
        "        \"Cargo\": np.random.choice(cargos, 3000),\n",
        "        \"Departamento\": np.random.choice(departamentos, 3000),\n",
        "        \"Genero\": np.random.choice(generos, 3000, p=[0.45, 0.45, 0.1]),\n",
        "        \"Salario\": np.random.randint(15000, 90000, 3000),\n",
        "        \"Sucursal\": np.random.choice(sucursales, 3000),\n",
        "        \"Años_Experiencia\": np.random.randint(0, 35, 3000),\n",
        "    }\n",
        "\n",
        "    df_rrhh = pd.DataFrame(data)\n",
        "    return df_rrhh\n",
        "\n",
        "df_rrhh = generar_dataset_rrhh()\n",
        "df_rrhh.columns#, df_rrhh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "6693980a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.\tEMPLEADO CON MAYOR SALARIO\n",
        "df_rrhh.sort_values(\"Salario\", ascending=False).head(1)\n",
        "\n",
        "# 2.\tEMPLEADOS CON MAS DE 10 AÑOS DE EXPERIENCIA QUE COBREN MAS DE 50000\n",
        "df_mas10año_mas50000= df_rrhh[(df_rrhh[\"Años_Experiencia\"] > 10) & (df_rrhh[\"Salario\"] > 50000)]\n",
        "\n",
        "# 3.\tSALARIO PROMEDIO POR DEPARTAMENTE\n",
        "df_rrhh.groupby(\"Departamento\")[\"Salario\"].mean()\n",
        "\n",
        "# 4.\tCANTIDAD DE EMPLEADO POR CUCURSAL\n",
        "df_rrhh['Sucursal'].value_counts()\n",
        "df_rrhh.groupby('Sucursal').size()\n",
        "\n",
        "# 5.\tEDAD PROMEDIO POR CARGO \n",
        "df_rrhh.groupby('Cargo')[\"Edad\"].mean()\n",
        "\n",
        "# 6.\tEMPLEADOS DE IT CON MENOS DE 30 AÑOS \n",
        "df_IT_mas30año= df_rrhh[(df_rrhh[\"Departamento\"] == \"IT\") & (df_rrhh[\"Edad\"] < 30)]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf758a44",
      "metadata": {},
      "source": [
        "## Pedidos restaurante"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7b39850",
      "metadata": {},
      "source": [
        "1.\tEncontrar los 5 pedidos más caros.\n",
        "2.\tFiltrar los pedidos pagados con tarjeta y con total mayor a 40€.\n",
        "3.\tCalcular ingreso total por cada plato.\n",
        "4.\tObtener el mesero con más pedidos atendidos.\n",
        "5.\tFiltrar pedidos de sushi con cantidad mayor a 2.\n",
        "6.\tObtener ingreso total por forma de pago.m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25ebf77a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Index(['Fecha', 'Cliente', 'Plato', 'Precio', 'Cantidad', 'Mesero',\n",
              "        'Forma_Pago', 'Total'],\n",
              "       dtype='object'),\n",
              "        Fecha    Cliente        Plato  Precio  Cantidad    Mesero Forma_Pago  \\\n",
              " 0 2024-02-08  Cliente B     Ensalada       8         4  Mesero 4     Paypal   \n",
              " 1 2024-02-21  Cliente D        Pizza      28         1  Mesero 1    Tarjeta   \n",
              " 2 2024-01-29  Cliente A     Ensalada      33         1  Mesero 4    Tarjeta   \n",
              " 3 2024-01-15  Cliente A        Pizza      23         4  Mesero 1    Tarjeta   \n",
              " 4 2024-02-12  Cliente C     Ensalada      10         1  Mesero 2   Efectivo   \n",
              " 5 2024-01-08  Cliente E        Sushi      37         2  Mesero 3    Tarjeta   \n",
              " 6 2024-01-21  Cliente A         Taco      44         2  Mesero 1   Efectivo   \n",
              " 7 2024-02-08  Cliente E     Ensalada      23         3  Mesero 2   Efectivo   \n",
              " 8 2024-02-27  Cliente A  Hamburguesa       5         1  Mesero 2    Tarjeta   \n",
              " 9 2024-01-19  Cliente B         Taco       9         2  Mesero 3    Tarjeta   \n",
              " \n",
              "    Total  \n",
              " 0     32  \n",
              " 1     28  \n",
              " 2     33  \n",
              " 3     92  \n",
              " 4     10  \n",
              " 5     74  \n",
              " 6     88  \n",
              " 7     69  \n",
              " 8      5  \n",
              " 9     18  )"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def generar_dataset_restaurante():\n",
        "    np.random.seed(42)\n",
        "    platos = [\"Pizza\", \"Hamburguesa\", \"Pasta\", \"Ensalada\", \"Sushi\", \"Taco\"]\n",
        "    clientes = [\"Cliente A\", \"Cliente B\", \"Cliente C\", \"Cliente D\", \"Cliente E\"]\n",
        "    meseros = [\"Mesero 1\", \"Mesero 2\", \"Mesero 3\", \"Mesero 4\"]\n",
        "    formas_pago = [\"Efectivo\", \"Tarjeta\", \"Paypal\"]\n",
        "\n",
        "    data = {\n",
        "        \"Fecha\": np.random.choice(pd.date_range(\"2024-01-01\", periods=60, freq=\"D\"), 1500),\n",
        "        \"Cliente\": np.random.choice(clientes, 1500),\n",
        "        \"Plato\": np.random.choice(platos, 1500),\n",
        "        \"Precio\": np.random.randint(5, 50, 1500),\n",
        "        \"Cantidad\": np.random.randint(1, 5, 1500),\n",
        "        \"Mesero\": np.random.choice(meseros, 1500),\n",
        "        \"Forma_Pago\": np.random.choice(formas_pago, 1500),\n",
        "    }\n",
        "\n",
        "    df_restaurante = pd.DataFrame(data)\n",
        "    df_restaurante[\"Total\"] = df_restaurante[\"Precio\"] * df_restaurante[\"Cantidad\"]\n",
        "    return df_restaurante\n",
        "\n",
        "df_restaurante = generar_dataset_restaurante()\n",
        "df_restaurante.columns#, df_restaurante.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59867f83",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Forma_Pago\n",
              "Efectivo    32282\n",
              "Paypal      33488\n",
              "Tarjeta     34555\n",
              "Name: Total, dtype: int64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1.\t5 PEDIDOS MÁS CAROS\n",
        "df_ordenado = df_restaurante.sort_values(\"Total\", ascending=False ).head(5)\n",
        "\n",
        "# 2.\tPEDIDOS CON TARJETA Y CON MÁS DE 40 EUROS TOTAL \n",
        "df_tarj_mas40 = df_restaurante[(df_restaurante[\"Forma_Pago\"] == \"Tarjeta\") & (df_restaurante[\"Total\"] > 40)]\n",
        "\n",
        "# 3.\tINGRESO TOTAL POR CADA PLATO\n",
        "df_restaurante.groupby(\"Plato\")[\"Total\"].sum()\n",
        "\n",
        "# 4.\tMESERO CON MÁS PEDIDOS ATENDIDOS\n",
        "df_restaurante.groupby(\"Mesero\")[\"Cantidad\"].sum().idxmax()\n",
        "'''df_restaurante[\"Mesero\"].value_counts().head(1)\n",
        "o equivalente:\n",
        "df_restaurante.groupby(\"Mesero\").size().sort_values(ascending=False).head(1)'''\n",
        "\n",
        "\n",
        "# 5.\tPEDIDO DE SUSHI CON CANTIDAD MAYOR QUE 2\n",
        "df_sushi_mas2 = df_restaurante[(df_restaurante[\"Plato\"] == \"Sushi\") & (df_restaurante[\"Cantidad\"] > 2)]\n",
        "\n",
        "# 6.\tINGRESO TOTAL POR FORMA DE PAGO \n",
        "df_restaurante.groupby(\"Forma_Pago\")[\"Total\"].sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "128e07e3",
      "metadata": {},
      "source": [
        "## Tráfico web"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec14045b",
      "metadata": {},
      "source": [
        "1.\tEncontrar la página con más visitas.\n",
        "2.\tCalcular el tiempo medio de sesión por dispositivo.\n",
        "3.\tFiltrar usuarios de Safari con sesiones mayores a 200 segundos.\n",
        "4.\tObtener la tasa de conversión total y por navegador.\n",
        "5.\tAnalizar el tráfico total en los últimos 30 días.m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "1196cac9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Index(['Fecha', 'Pagina', 'Navegador', 'Dispositivo', 'Tiempo_Sesion',\n",
              "        'Conversion'],\n",
              "       dtype='object'),\n",
              "        Fecha     Pagina Navegador Dispositivo  Tiempo_Sesion  Conversion\n",
              " 0 2023-04-13  /contacto      Edge      Tablet            274           0\n",
              " 1 2023-06-29  /contacto    Chrome       Móvil             17           0\n",
              " 2 2023-04-03      /blog   Firefox       Móvil            181           0\n",
              " 3 2023-01-15  /contacto    Chrome      Tablet            204           0\n",
              " 4 2023-04-17  /contacto    Safari      Tablet            278           0)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def generar_dataset_trafico():\n",
        "    np.random.seed(42)\n",
        "    paginas = [\"/home\", \"/contacto\", \"/productos\", \"/blog\", \"/checkout\"]\n",
        "    navegadores = [\"Chrome\", \"Firefox\", \"Safari\", \"Edge\"]\n",
        "    dispositivos = [\"Móvil\", \"Tablet\", \"PC\"]\n",
        "\n",
        "    data = {\n",
        "        \"Fecha\": np.random.choice(pd.date_range(\"2023-01-01\", periods=180, freq=\"D\"), 5000),\n",
        "        \"Pagina\": np.random.choice(paginas, 5000),\n",
        "        \"Navegador\": np.random.choice(navegadores, 5000),\n",
        "        \"Dispositivo\": np.random.choice(dispositivos, 5000),\n",
        "        \"Tiempo_Sesion\": np.random.randint(10, 300, 5000),\n",
        "        \"Conversion\": np.random.choice([0, 1], 5000, p=[0.9, 0.1]),\n",
        "    }\n",
        "\n",
        "    df_trafico = pd.DataFrame(data)\n",
        "    return df_trafico\n",
        "\n",
        "df_trafico = generar_dataset_trafico()\n",
        "df_trafico.columns, df_trafico.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29de1739",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tráfico total en los últimos 30 días 899\n"
          ]
        }
      ],
      "source": [
        "# 1. PAGINA CON MAS VISITAS\n",
        "df_trafico[\"Pagina\"].value_counts().idxmax()\n",
        "'''df_trafico.groupby(\"Pagina\").size().idxmax()'''\n",
        "\n",
        "# 2. TIEMPO MEDIO DE SESIÓN POR DISPONSITIVO\n",
        "df_trafico.groupby(\"Dispositivo\")[\"Tiempo_Sesion\"].mean()\n",
        "\n",
        "# 3. USUARIOS DE SAFARI CON SESIONES MAYORES A 200s\n",
        "df_saf_mas200s = df_trafico[(df_trafico[\"Navegador\"] == \"Safari\") & (df_trafico[\"Tiempo_Sesion\"] > 200)]\n",
        "\n",
        "# 4. TASA(PROMEDIO) DE CONVERSIÓN TOTAL Y POR NAVEGADOR\n",
        "tasa_total = df_trafico[\"Conversion\"].mean() #calcular la tasa de conversión total de todo el tráfico.\n",
        "tasa_por_navegador = df_trafico.groupby(\"Navegador\")[\"Conversion\"].mean()\n",
        "\n",
        "# 5. ANALIZAR EL TRAFICO TOTAL EN LOS ULT 30 DÍAS\n",
        "fecha_max = df_trafico[\"Fecha\"].max()\n",
        "ultimos_30 = fecha_max - pd.Timedelta(days=30)\n",
        "df_ultimos_30 = df_trafico[df_trafico[\"Fecha\"] >= ultimos_30]\n",
        "trafico_total_30dias = len(df_ultimos_30) #cuantas filas hay \n",
        "print(f\"Tráfico total en los últimos 30 días {trafico_total_30dias}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f340806",
      "metadata": {
        "lang": "en"
      },
      "source": [
        "# Métodos habituales de Pandas\n",
        "```python\n",
        "df.head() # imprime la cabecera, por defecto 5 filas\n",
        "df.tail() # establece la cola, por defecto 5 filas\n",
        "df.describe() # descripción estadística\n",
        "df.info() # información del df\n",
        "df.columns # muestra la columna\n",
        "df.index # muestra el índice\n",
        "df.dtypes # muestra los tipos de datos de la columna\n",
        "df.plot() # hace un gráfico\n",
        "df.hist() # hace un histograma\n",
        "df.col.value_counts() # cuenta los valores únicos de una columna\n",
        "df.col.unique() # devuelve valores únicos de una columna\n",
        "df.copy() # copia el df\n",
        "df.drop() # elimina columnas o filas (axis=0,1)\n",
        "df.dropna() # elimina nulos\n",
        "df.fillna() # rellena nulos\n",
        "df.shape # dimensiones del df\n",
        "df._get_numeric_data() # selecciona numérico columnas\n",
        "df.rename() # renombrar columnas\n",
        "df.str.replace() # reemplazar columnas de cadenas\n",
        "df.astype(dtype='float32') # cambiar el tipo de datos\n",
        "df.iloc[] # localizar por índice\n",
        "df.loc[] # localizar por elemento\n",
        "df.transpose() # transpone el df\n",
        "df.T\n",
        "df.sample(n, frac) # muestra de df\n",
        "df.col.sum() # suma de una columna\n",
        "df.col.max() # máximo de una columna\n",
        "df.col.min() # mínimo de una columna\n",
        "df[col] # seleccionar columna\n",
        "df.col\n",
        "df.isnull() # valores nulos\n",
        "df.isna()\n",
        "df.notna() # valores no nulos\n",
        "df.drop_duplicates() # eliminar duplicados\n",
        "df.reset_index(inplace=True) # restablecer el índice y sobrescribir\n",
        "df.sort_values(by=\"columna\", ascending=True, inplace=False) #ordenar por una columna\n",
        "df.groupby(\"Categoria\") #agrupar por categoria\n",
        "df.groupby(\"grupo\").size() #cuanta las filas por grupo\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "7f331cc1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['T',\n",
              " 'abs',\n",
              " 'add',\n",
              " 'add_prefix',\n",
              " 'add_suffix',\n",
              " 'agg',\n",
              " 'aggregate',\n",
              " 'align',\n",
              " 'all',\n",
              " 'any',\n",
              " 'apply',\n",
              " 'argmax',\n",
              " 'argmin',\n",
              " 'argsort',\n",
              " 'array',\n",
              " 'asfreq',\n",
              " 'asof',\n",
              " 'astype',\n",
              " 'at',\n",
              " 'at_time',\n",
              " 'attrs',\n",
              " 'autocorr',\n",
              " 'axes',\n",
              " 'backfill',\n",
              " 'between',\n",
              " 'between_time',\n",
              " 'bfill',\n",
              " 'bool',\n",
              " 'case_when',\n",
              " 'cat',\n",
              " 'clip',\n",
              " 'combine',\n",
              " 'combine_first',\n",
              " 'compare',\n",
              " 'convert_dtypes',\n",
              " 'copy',\n",
              " 'corr',\n",
              " 'count',\n",
              " 'cov',\n",
              " 'cummax',\n",
              " 'cummin',\n",
              " 'cumprod',\n",
              " 'cumsum',\n",
              " 'describe',\n",
              " 'diff',\n",
              " 'div',\n",
              " 'divide',\n",
              " 'divmod',\n",
              " 'dot',\n",
              " 'drop',\n",
              " 'drop_duplicates',\n",
              " 'droplevel',\n",
              " 'dropna',\n",
              " 'dt',\n",
              " 'dtype',\n",
              " 'dtypes',\n",
              " 'duplicated',\n",
              " 'empty',\n",
              " 'eq',\n",
              " 'equals',\n",
              " 'ewm',\n",
              " 'expanding',\n",
              " 'explode',\n",
              " 'factorize',\n",
              " 'ffill',\n",
              " 'fillna',\n",
              " 'filter',\n",
              " 'first',\n",
              " 'first_valid_index',\n",
              " 'flags',\n",
              " 'floordiv',\n",
              " 'ge',\n",
              " 'get',\n",
              " 'groupby',\n",
              " 'gt',\n",
              " 'hasnans',\n",
              " 'head',\n",
              " 'hist',\n",
              " 'iat',\n",
              " 'idxmax',\n",
              " 'idxmin',\n",
              " 'iloc',\n",
              " 'index',\n",
              " 'infer_objects',\n",
              " 'info',\n",
              " 'interpolate',\n",
              " 'is_monotonic_decreasing',\n",
              " 'is_monotonic_increasing',\n",
              " 'is_unique',\n",
              " 'isin',\n",
              " 'isna',\n",
              " 'isnull',\n",
              " 'item',\n",
              " 'items',\n",
              " 'keys',\n",
              " 'kurt',\n",
              " 'kurtosis',\n",
              " 'last',\n",
              " 'last_valid_index',\n",
              " 'le',\n",
              " 'list',\n",
              " 'loc',\n",
              " 'lt',\n",
              " 'map',\n",
              " 'mask',\n",
              " 'max',\n",
              " 'mean',\n",
              " 'median',\n",
              " 'memory_usage',\n",
              " 'min',\n",
              " 'mod',\n",
              " 'mode',\n",
              " 'mul',\n",
              " 'multiply',\n",
              " 'name',\n",
              " 'nbytes',\n",
              " 'ndim',\n",
              " 'ne',\n",
              " 'nlargest',\n",
              " 'notna',\n",
              " 'notnull',\n",
              " 'nsmallest',\n",
              " 'nunique',\n",
              " 'pad',\n",
              " 'pct_change',\n",
              " 'pipe',\n",
              " 'plot',\n",
              " 'pop',\n",
              " 'pow',\n",
              " 'prod',\n",
              " 'product',\n",
              " 'quantile',\n",
              " 'radd',\n",
              " 'rank',\n",
              " 'ravel',\n",
              " 'rdiv',\n",
              " 'rdivmod',\n",
              " 'reindex',\n",
              " 'reindex_like',\n",
              " 'rename',\n",
              " 'rename_axis',\n",
              " 'reorder_levels',\n",
              " 'repeat',\n",
              " 'replace',\n",
              " 'resample',\n",
              " 'reset_index',\n",
              " 'rfloordiv',\n",
              " 'rmod',\n",
              " 'rmul',\n",
              " 'rolling',\n",
              " 'round',\n",
              " 'rpow',\n",
              " 'rsub',\n",
              " 'rtruediv',\n",
              " 'sample',\n",
              " 'searchsorted',\n",
              " 'sem',\n",
              " 'set_axis',\n",
              " 'set_flags',\n",
              " 'shape',\n",
              " 'shift',\n",
              " 'size',\n",
              " 'skew',\n",
              " 'sort_index',\n",
              " 'sort_values',\n",
              " 'sparse',\n",
              " 'squeeze',\n",
              " 'std',\n",
              " 'str',\n",
              " 'struct',\n",
              " 'sub',\n",
              " 'subtract',\n",
              " 'sum',\n",
              " 'swapaxes',\n",
              " 'swaplevel',\n",
              " 'tail',\n",
              " 'take',\n",
              " 'to_clipboard',\n",
              " 'to_csv',\n",
              " 'to_dict',\n",
              " 'to_excel',\n",
              " 'to_frame',\n",
              " 'to_hdf',\n",
              " 'to_json',\n",
              " 'to_latex',\n",
              " 'to_list',\n",
              " 'to_markdown',\n",
              " 'to_numpy',\n",
              " 'to_period',\n",
              " 'to_pickle',\n",
              " 'to_sql',\n",
              " 'to_string',\n",
              " 'to_timestamp',\n",
              " 'to_xarray',\n",
              " 'tolist',\n",
              " 'transform',\n",
              " 'transpose',\n",
              " 'truediv',\n",
              " 'truncate',\n",
              " 'tz_convert',\n",
              " 'tz_localize',\n",
              " 'unique',\n",
              " 'unstack',\n",
              " 'update',\n",
              " 'value_counts',\n",
              " 'values',\n",
              " 'var',\n",
              " 'view',\n",
              " 'where',\n",
              " 'xs']"
            ]
          },
          "execution_count": 148,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Métodos de los DATAFRAMES\n",
        "\n",
        "[i for i in dir(pd.Series) if not i.startswith('_')]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "stylish-jefferson",
      "metadata": {},
      "source": [
        "## Materiales adicionales\n",
        "\n",
        "* [¡Lea la documentación!](https://pandas.pydata.org/pandas-docs/stable/index.html)\n",
        "* [Hoja de trucos](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)\n",
        "* [Ejercicios para practicar](https://github.com/guipsamora/pandas_exercises)\n",
        "* [Más información sobre fusión, concatenación y unión](https://realpython.com/pandas-merge-join-and-concat/#pandas-join-combining-data-on-a-column-or-index). Y [¡aún más!](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html)"
      ]
    }
  ],
  "metadata": {
    "author": "https://github.com/breogann",
    "created": "2021",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "nbTranslate": {
      "displayLangs": [
        "en",
        "es"
      ],
      "hotkey": "alt-a",
      "langInMainMenu": true,
      "sourceLang": "es",
      "targetLang": "en",
      "useGoogleTranslate": true
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "269.766px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
